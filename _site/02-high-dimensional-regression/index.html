






<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="last-modified" content="2024-02-26 23:12:36 +0000">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- meta "search-domain" used for google site search function google_search() -->
    <meta name="search-domain" value="">
    <link rel="stylesheet" type="text/css" href="../assets/css/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/lesson.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/syntax.css" />
     <link rel="stylesheet" type="text/css" href="../assets/css/fonts.css" />
    
    <link rel="stylesheet" type="text/css" href="../assets/css/katex.min.css" />
    
    <link rel="license" href="#license-info" />

    



    <!-- Favicons for everyone -->
    <link rel="apple-touch-icon-precomposed" sizes="57x57" href="../assets/favicons/incubator/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../assets/favicons/incubator/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../assets/favicons/incubator/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../assets/favicons/incubator/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon-precomposed" sizes="60x60" href="../assets/favicons/incubator/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon-precomposed" sizes="120x120" href="../assets/favicons/incubator/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon-precomposed" sizes="76x76" href="../assets/favicons/incubator/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../assets/favicons/incubator/apple-touch-icon-152x152.png" />
    <link rel="icon" type="image/png" href="../assets/favicons/incubator/favicon-196x196.png" sizes="196x196" />
    <link rel="icon" type="image/png" href="../assets/favicons/incubator/favicon-96x96.png" sizes="96x96" />
    <link rel="icon" type="image/png" href="../assets/favicons/incubator/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="../assets/favicons/incubator/favicon-16x16.png" sizes="16x16" />
    <link rel="icon" type="image/png" href="../assets/favicons/incubator/favicon-128.png" sizes="128x128" />
    <meta name="application-name" content="The Carpentries Incubator - High dimensional statistics with R"/>
    <meta name="msapplication-TileColor" content="#FFFFFF" />
    <meta name="msapplication-TileImage" content="../assets/favicons/incubator/mstile-144x144.png" />
    <meta name="msapplication-square70x70logo" content="../assets/favicons/incubator/mstile-70x70.png" />
    <meta name="msapplication-square150x150logo" content="../assets/favicons/incubator/mstile-150x150.png" />
    <meta name="msapplication-wide310x150logo" content="../assets/favicons/incubator/mstile-310x150.png" />
    <meta name="msapplication-square310x310logo" content="../assets/favicons/incubator/mstile-310x310.png" />


    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->
  <title>
  Regression with many outcomes &ndash; High dimensional statistics with R
  </title>

  </head>
  <body>
    


<div class="panel panel-default life-cycle">
  <div id="life-cycle" class="panel-body alpha">
    This lesson is in the early stages of development (Alpha version)
  </div>
</div>





    <div class="container">
      
















  
  










<nav class="navbar navbar-default">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      
      
      <a href="../index.html" class="pull-left">
        <img class="navbar-logo" src="../assets/img/incubator-logo-blue.svg" alt="The Carpentries Incubator logo" />
      </a>
      

      
      <a class="navbar-brand" href="../index.html">Home</a>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

	
        <li><a href="../CODE_OF_CONDUCT.html">Code of Conduct</a></li>

        
	
        <li><a href="../setup.html">Setup</a></li>

        
        
        <li class="dropdown">
          <a href="../" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Episodes <span class="caret"></span></a>
          <ul class="dropdown-menu">
            
            
            <li><a href="../01-introduction-to-high-dimensional-data/index.html">Introduction to high-dimensional data</a></li>
            
            
            <li><a href="../02-high-dimensional-regression/index.html">Regression with many outcomes</a></li>
            
            
            <li><a href="../03-regression-regularisation/index.html">Regularised regression</a></li>
            
            
            <li><a href="../04-principal-component-analysis/index.html">Principal component analysis</a></li>
            
            
            <li><a href="../05-factor-analysis/index.html">Factor analysis</a></li>
            
            
            <li><a href="../06-k-means/index.html">K-means</a></li>
            
            
            <li><a href="../07-hierarchical/index.html">Hierarchical clustering</a></li>
            
	    <li role="separator" class="divider"></li>
            <li><a href="../aio/index.html">All in one page (Beta)</a></li>
          </ul>
        </li>
        
	

	
	
        <li class="dropdown">
          <a href="../" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Extras <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="../reference.html">Reference</a></li>
            
            
            <li><a href="../about/index.html">About</a></li>
            
            
            <li><a href="../figures/index.html">Figures</a></li>
            
            
            <li><a href="../guide/index.html">Instructor Notes</a></li>
            
            
            <li><a href="../slides/index.html">Lecture slides</a></li>
            
          </ul>
        </li>
	

	
        <li><a href="../LICENSE.html">License</a></li>
	
	
	<li><a href="/edit//_episodes_rmd/02-high-dimensional-regression.Rmd" data-checker-ignore>Improve this page <span class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a></li>
	
	
      </ul>
      <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form>
    </div>
  </div>
</nav>

      


<div class="alert alert-info text-center" role="alert">
  This lesson is part of
  <a href="https://github.com/carpentries-incubator/proposals/#the-carpentries-incubator" data-checker-ignore>
    The Carpentries Incubator</a>, a place to share and use each other's
  Carpentries-style lessons. <strong>This lesson has not been reviewed by and is
  not endorsed by The Carpentries</strong>.
</div>




      

















  
  











<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="../01-introduction-to-high-dimensional-data/index.html"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
    <h3 class="maintitle"><a href="../">High dimensional statistics with R</a></h3>
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="../03-regression-regularisation/index.html"><span class="glyphicon glyphicon-menu-right" aria-hidden="true"></span><span class="sr-only">next episode</span></a>
      
    </h3>
  </div>
</div>

<article>
<div class="row">
  <div class="col-md-1">
  </div>
  <div class="col-md-10">
    <h1 class="maintitle">Regression with many outcomes</h1>
  </div>
  <div class="col-md-1">
  </div>
</div>












<blockquote class="objectives">
  <h2>Overview</h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 60 min
      <br/>
      <strong>Exercises:</strong> 30 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can we apply linear regression in a high-dimensional setting?</p>
</li>
	
	<li><p>How can we benefit from the fact that we have many outcomes?</p>
</li>
	
	<li><p>How can we control for the fact that we do many tests?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Perform and critically analyse high dimensional regression.</p>
</li>
	
	<li><p>Understand methods for shrinkage of noise parameters in high-dimensional regression.</p>
</li>
	
	<li><p>Perform multiple testing adjustment.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<h1 id="dna-methylation-data">DNA methylation data</h1>

<p>For the following few episodes, we will be working with human DNA
methylation data from flow-sorted blood samples. DNA methylation assays
measure, for each of many sites in the genome, the proportion of DNA
that carries a methyl mark (a chemical modification that does not alter the 
DNA sequence). In this case, the methylation data come in
the form of a matrix of normalised methylation levels (M-values), where negative
values correspond to unmethylated DNA and positive values correspond to
methylated DNA. Along with this, we have a number of sample phenotypes
(eg, age in years, BMI).</p>

<p>Let’s read in the data for this episode:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="s2">"here"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"minfi"</span><span class="p">)</span><span class="w">
</span><span class="n">methylation</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">readRDS</span><span class="p">(</span><span class="n">here</span><span class="p">(</span><span class="s2">"data/methylation.rds"</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<p>Note: the code that we used to download these data from its source is available
<a href="https://github.com/carpentries-incubator/high-dimensional-stats-r/blob/main/data/methylation.R">here</a></p>

<p>This <code class="language-plaintext highlighter-rouge">methylation</code> object is a <code class="language-plaintext highlighter-rouge">GenomicRatioSet</code>, a Bioconductor data
object derived from the <code class="language-plaintext highlighter-rouge">SummarizedExperiment</code> class. These
<code class="language-plaintext highlighter-rouge">SummarizedExperiment</code> objects contain <code class="language-plaintext highlighter-rouge">assay</code>s, in this case
normalised methylation levels, and optional sample-level <code class="language-plaintext highlighter-rouge">colData</code> and
feature-level <code class="language-plaintext highlighter-rouge">metadata</code>. These objects are very convenient to contain
all of the information about a dataset in a high-throughput context. If
you would like more detail on these objects it may be useful to consult
the <a href="https://www.bioconductor.org/packages/release/bioc/vignettes/SummarizedExperiment/inst/doc/SummarizedExperiment.html">vignettes on
Bioconductor</a>.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">methylation</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class: GenomicRatioSet 
dim: 5000 37 
metadata(0):
assays(2): M CN
rownames(5000): cg00075967 cg00374717 ... cg08482167 cg13174700
rowData names(0):
colnames(37): 201868500150_R01C01 201868500150_R03C01 ...
  201870610111_R06C01 201870610111_R07C01
colData names(14): Sample_Well Sample_Name ... Array Slide
Annotation
  array: IlluminaHumanMethylationEPIC
  annotation: ilm10b4.hg19
Preprocessing
  Method: Raw (no normalization or bg correction)
  minfi version: 1.38.0
  Manifest version: 0.3.0
</code></pre></div></div>

<p>You can see in this output that this object has a <code class="language-plaintext highlighter-rouge">dim()</code> of
$5000 \times 37$, meaning it has
5000 features and 37 columns. To
extract the matrix of methylation M-values, we can use the
<code class="language-plaintext highlighter-rouge">assay()</code> function. One thing to bear in mind with these objects (and
data structures for computational biology in R generally) is that in the
matrix of methylation data, samples or observations are stored as
columns, while features (in this case, sites in the genome) are stored as rows.
This is in contrast to usual tabular data, where features or variables
are stored as columns and observations are stored as rows.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">methyl_mat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">assay</span><span class="p">(</span><span class="n">methylation</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>The distribution of these M-values looks like this:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hist</span><span class="p">(</span><span class="n">methyl_mat</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"FD"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"M-value"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-histx-1.png" alt="Histogram of M-values for all features. The distribution appears to be bimodal, with a large number of unmethylated features as well as many methylated features, and many intermediate features." width="432" />
<p class="caption">Methylation levels are generally bimodally distributed.</p>
</div>

<p>You can see that there are two peaks in this distribution, corresponding
to features which are largely unmethylated and methylated, respectively.</p>

<p>Similarly, we can examine the <code class="language-plaintext highlighter-rouge">colData()</code>, which represents the
sample-level metadata we have relating to these data. In this case, the
metadata, phenotypes, and groupings in the <code class="language-plaintext highlighter-rouge">colData</code> look like this for
the first 6 samples:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">knitr</span><span class="o">::</span><span class="n">kable</span><span class="p">(</span><span class="n">head</span><span class="p">(</span><span class="n">colData</span><span class="p">(</span><span class="n">methylation</span><span class="p">)),</span><span class="w"> </span><span class="n">row.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Sample_Well</th>
      <th style="text-align: left">Sample_Name</th>
      <th style="text-align: right">purity</th>
      <th style="text-align: left">Sex</th>
      <th style="text-align: right">Age</th>
      <th style="text-align: right">weight_kg</th>
      <th style="text-align: right">height_m</th>
      <th style="text-align: right">bmi</th>
      <th style="text-align: left">bmi_clas</th>
      <th style="text-align: left">Ethnicity_wide</th>
      <th style="text-align: left">Ethnic_self</th>
      <th style="text-align: left">smoker</th>
      <th style="text-align: left">Array</th>
      <th style="text-align: right">Slide</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">A07</td>
      <td style="text-align: left">PCA0612</td>
      <td style="text-align: right">94</td>
      <td style="text-align: left">M</td>
      <td style="text-align: right">39</td>
      <td style="text-align: right">88.45051</td>
      <td style="text-align: right">1.8542</td>
      <td style="text-align: right">25.72688</td>
      <td style="text-align: left">Overweight</td>
      <td style="text-align: left">Mixed</td>
      <td style="text-align: left">Hispanic</td>
      <td style="text-align: left">No</td>
      <td style="text-align: left">R01C01</td>
      <td style="text-align: right">201868500150</td>
    </tr>
    <tr>
      <td style="text-align: left">C07</td>
      <td style="text-align: left">NKpan2510</td>
      <td style="text-align: right">95</td>
      <td style="text-align: left">M</td>
      <td style="text-align: right">49</td>
      <td style="text-align: right">81.19303</td>
      <td style="text-align: right">1.6764</td>
      <td style="text-align: right">28.89106</td>
      <td style="text-align: left">Overweight</td>
      <td style="text-align: left">Indo-European</td>
      <td style="text-align: left">Caucasian</td>
      <td style="text-align: left">No</td>
      <td style="text-align: left">R03C01</td>
      <td style="text-align: right">201868500150</td>
    </tr>
    <tr>
      <td style="text-align: left">E07</td>
      <td style="text-align: left">WB1148</td>
      <td style="text-align: right">95</td>
      <td style="text-align: left">M</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">80.28585</td>
      <td style="text-align: right">1.7526</td>
      <td style="text-align: right">26.13806</td>
      <td style="text-align: left">Overweight</td>
      <td style="text-align: left">Indo-European</td>
      <td style="text-align: left">Persian</td>
      <td style="text-align: left">No</td>
      <td style="text-align: left">R05C01</td>
      <td style="text-align: right">201868500150</td>
    </tr>
    <tr>
      <td style="text-align: left">G07</td>
      <td style="text-align: left">B0044</td>
      <td style="text-align: right">97</td>
      <td style="text-align: left">M</td>
      <td style="text-align: right">49</td>
      <td style="text-align: right">82.55381</td>
      <td style="text-align: right">1.7272</td>
      <td style="text-align: right">27.67272</td>
      <td style="text-align: left">Overweight</td>
      <td style="text-align: left">Indo-European</td>
      <td style="text-align: left">Caucasian</td>
      <td style="text-align: left">No</td>
      <td style="text-align: left">R07C01</td>
      <td style="text-align: right">201868500150</td>
    </tr>
    <tr>
      <td style="text-align: left">H07</td>
      <td style="text-align: left">NKpan1869</td>
      <td style="text-align: right">95</td>
      <td style="text-align: left">F</td>
      <td style="text-align: right">33</td>
      <td style="text-align: right">87.54333</td>
      <td style="text-align: right">1.7272</td>
      <td style="text-align: right">29.34525</td>
      <td style="text-align: left">Overweight</td>
      <td style="text-align: left">Indo-European</td>
      <td style="text-align: left">Caucasian</td>
      <td style="text-align: left">No</td>
      <td style="text-align: left">R08C01</td>
      <td style="text-align: right">201868500150</td>
    </tr>
    <tr>
      <td style="text-align: left">B03</td>
      <td style="text-align: left">NKpan1850</td>
      <td style="text-align: right">93</td>
      <td style="text-align: left">F</td>
      <td style="text-align: right">21</td>
      <td style="text-align: right">87.54333</td>
      <td style="text-align: right">1.6764</td>
      <td style="text-align: right">31.15070</td>
      <td style="text-align: left">Obese</td>
      <td style="text-align: left">Mixed</td>
      <td style="text-align: left">Finnish/Creole</td>
      <td style="text-align: left">No</td>
      <td style="text-align: left">R02C01</td>
      <td style="text-align: right">201868590193</td>
    </tr>
  </tbody>
</table>

<p>In this episode, we will focus on the association between age and
methylation. The following heatmap summarises age and methylation levels 
available in the Prostate dataset:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">age</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">methylation</span><span class="o">$</span><span class="n">Age</span><span class="w">

</span><span class="n">library</span><span class="p">(</span><span class="s2">"ComplexHeatmap"</span><span class="p">)</span><span class="w">
</span><span class="n">order</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">order</span><span class="p">(</span><span class="n">age</span><span class="p">)</span><span class="w">
</span><span class="n">age_ord</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">age</span><span class="p">[</span><span class="n">order</span><span class="p">]</span><span class="w">
</span><span class="n">methyl_mat_ord</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">methyl_mat</span><span class="p">[,</span><span class="w"> </span><span class="n">order</span><span class="p">]</span><span class="w">

</span><span class="n">Heatmap</span><span class="p">(</span><span class="n">methyl_mat_ord</span><span class="p">,</span><span class="w">
        </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"M-value"</span><span class="p">,</span><span class="w">
        </span><span class="n">cluster_columns</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w">
        </span><span class="n">show_row_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w">
        </span><span class="n">show_column_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w">
        </span><span class="n">row_title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Feature"</span><span class="p">,</span><span class="w">
        </span><span class="n">column_title</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="s2">"Sample"</span><span class="p">,</span><span class="w">
        </span><span class="n">top_annotation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">columnAnnotation</span><span class="p">(</span><span class="n">age</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">age_ord</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-heatmap-1.png" alt="Heatmap of methylation values across all features. Samples are ordered according to age." width="432" />
<p class="caption">Visualising the data as a heatmap, it's clear that there's too many models to fit 'by hand'.</p>
</div>
<p>Depending on the scientific question of interest, two types of high-dimensional 
problems could be explored in this context:</p>

<ol>
  <li>
    <p>To predict age using methylation levels as predictors. In this case, we would 
have a single outcome (age) which will be predicted using 5000 covariates 
(methylation levels across the genome).</p>
  </li>
  <li>
    <p>To predict methylation levels using age as a predictor. In this case, we 
would have 5000 outcomes (methylation levels across the genome) and a single 
covariate (age).</p>
  </li>
</ol>

<p>The examples in this episode will focus on the second type of problem, whilst 
the next episode will focus on the first.</p>

<blockquote class="challenge">
  <h2 id="challenge-1">Challenge 1</h2>

  <p>Why can we not just fit many linear regression models, one for each of the columns
in the <code class="language-plaintext highlighter-rouge">colData</code> above against each of the features in the matrix of
assays, and choose all of the significant results at a p-value of
0.05?</p>

  <blockquote class="solution">
    <h2 id="solution">Solution</h2>

    <p>There are a number of problems that this kind of approach presents.
For example: 1. Without a research question in mind when creating a
model, it’s not clear how we can interpret each model, and
rationalising the results after the fact can be dangerous; it’s easy
to make up a “story” that isn’t grounded in anything but the fact
that we have significant findings. 2. We may not have a representative
sample for each of these covariates. For example, we may have very
small sample sizes for some ethnicities, leading to spurious
findings. 3. If we perform 5000 tests for each of
14 variables, even if there were no true
associations in the data, we’d be likely to observe some strong
spurious associations that arise just from random noise.</p>

  </blockquote>
</blockquote>

<blockquote class="callout">
  <h2 id="measuring-dna-methylation">Measuring DNA Methylation</h2>

  <p>DNA methylation is an epigenetic modification of DNA. Generally, we
are interested in the proportion of methylation at many sites or
regions in the genome. DNA methylation microarrays, as we are using
here, measure DNA methylation using two-channel microarrays, where one
channel captures signal from methylated DNA and the other captures
unmethylated signal. These data can be summarised as “Beta values”
($\beta$ values), which is the ratio of the methylated signal to the
total signal (methylated plus unmethylated). The $\beta$ value for
site $i$ is calculated as</p>

\[\beta_i = \frac{
        m_i
    } {
        u_{i} + m_{i}
    }\]

  <p>where $m_i$ is the methylated signal for site $i$ and $u_i$ is the
unmethylated signal for site $i$. $\beta$ values take on a value in
the range $[0, 1]$, with 0 representing a completely unmethylated site
and 1 representing a completely methylated site.</p>

  <p>The M-values we use here are the $\log_2$ ratio of methylated versus
unmethylated signal:</p>

\[M_i = \log_2\left(\frac{m_i}{u_i}\right)\]

  <p>M-values are not bounded to an interval as Beta values are, and
therefore can be easier to work with in statistical models.</p>
</blockquote>

<h1 id="regression-with-many-outcomes">Regression with many outcomes</h1>

<p>In high-throughput studies, it is common to have one or more phenotypes
or groupings that we want to relate to features of interest (eg, gene
expression, DNA methylation levels). In general, we want to identify
differences in the features of interest that are related to a phenotype
or grouping of our samples. Identifying features of interest that vary
along with phenotypes or groupings can allow us to understand how
phenotypes arise or manifest. Analysis of this type is sometimes referred 
to using the term <em>differential analysis</em>.</p>

<p>For example, we might want to identify genes that are expressed at a
higher level in mutant mice relative to wild-type mice to understand the
effect of a mutation on cellular phenotypes. Alternatively, we might
have samples from a set of patients, and wish to identify epigenetic
features that are different in young patients relative to old patients,
to help us understand how ageing manifests.</p>

<p>Using linear regression, it is possible to identify differences like
these. However, high-dimensional data like the ones we’re working with
require some special considerations. A primary consideration, as we saw
above, is that there are far too many features to fit each one-by-one as
we might do when analysing low-dimensional datasets (for example using
<code class="language-plaintext highlighter-rouge">lm</code> on each feature and checking the linear model assumptions). A
secondary consideration is that statistical approaches may behave
slightly differently in very high-dimensional data, compared to
low-dimensional data. A third consideration is the speed at which we can
actually compute statistics for data this large – methods optimised for
low-dimensional data may be very slow when applied to high-dimensional
data.</p>

<p>Ideally when performing regression, we want to identify cases like this,
where there is a clear association, and we probably “don’t need”
statistics:</p>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-example1-1.png" alt="An example of a strong linear association between a continuous phenotype (age) on the x-axis and a feature of interest (DNA methylation at a given locus) on the y-axis. A strong linear relationship with a positive slope exists between the two." width="432" />
<p class="caption">A scatter plot of age and a feature of interest.</p>
</div>

<p>or equivalently for a discrete covariate:</p>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-example2-1.png" alt="An example of a strong linear association between a discrete phenotype (group) on the x-axis and a feature of interest (DNA methylation at a given locus) on the y-axis. The two groups clearly differ with respect to DNA methylation." width="432" />
<p class="caption">A scatter plot of a grouping and a feature of interest.</p>
</div>

<p>However, often due to small differences and small sample sizes, the
problem is more difficult:</p>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-example3-1.png" alt="An example of a strong linear association between a discrete phenotype (group) on the x-axis and a feature of interest (DNA methylation at a given locus) on the y-axis. The two groups seem to differ with respect to DNA methylation, but the relationship is weak." width="432" />
<p class="caption">A scatter plot of a grouping and a feature of interest.</p>
</div>

<p>And, of course, we often have an awful lot of features and need to
prioritise a subset of them! We need a rigorous way to prioritise genes
for further analysis.</p>

<h1 id="fitting-a-linear-model">Fitting a linear model</h1>

<p>So, in the data we have read in, we have a matrix of methylation values
$X$ and a vector of ages, $y$. One way to model this is to see if we can
use age to predict the expected (average) methylation value for sample
$j$ at a given locus $i$, which we can write as $X_{ij}$. We can write
that model as:</p>

\[\mathbf{E}(X_{ij}) = \beta_0 + \beta_1 \text{Age}_j\]

<p>where $\text{Age}_j$ is the age of sample $j$. In this model, $\beta_1$
represents the unit change in mean methylation level for each unit
(year) change in age. For a specific CpG, we can fit this model and get more 
information from the model object. For illustration purposes, here we 
arbitrarily select the first CpG in the <code class="language-plaintext highlighter-rouge">methyl_mat</code> matrix (the one on its first row).</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">age</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">methylation</span><span class="o">$</span><span class="n">Age</span><span class="w">
</span><span class="c1"># methyl_mat[1, ] indicates that the 1st CpG will be used as outcome variable</span><span class="w">
</span><span class="n">lm_age_methyl1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">methyl_mat</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">age</span><span class="p">)</span><span class="w">
</span><span class="n">lm_age_methyl1</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Call:
lm(formula = methyl_mat[1, ] ~ age)

Coefficients:
(Intercept)          age  
   0.902334     0.008911  
</code></pre></div></div>

<p>We now have estimates for the expected methylation level when age equals
0 (the intercept) and the change in methylation level for a unit change
in age (the slope). We could plot this linear model:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">age</span><span class="p">,</span><span class="w"> </span><span class="n">methyl_mat</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Age"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Methylation level"</span><span class="p">,</span><span class="w"> </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">lm_age_methyl1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-plot-lm-methyl1-1.png" alt="An example of the relationship between age (x-axis) and methylation levels (y-axis) for an arbitrarily selected CpG. In this case, the y-axis shows methylation levels for the first CpG in our data. The black line shows the fitted regression line (based on the intercept and slope estimates shown above). For this feature, we can see that there is no strong relationship between methylation and age." width="432" />
<p class="caption">A scatter plot of age versus the methylation level for an arbitrarily selected CpG side (the one stored as the first column of methyl_mat). Each dot represents an individual. The black line represents the estimated linear model.</p>
</div>

<p>For this feature, we can see that there is no strong relationship
between methylation and age. We could try to repeat this for every
feature in our dataset; however, we have a lot of features! We need an
approach that allows us to assess associations between all of these
features and our outcome while addressing the three considerations we
outlined previously. Before we introduce this approach, let’s go into
detail about how we generally check whether the results of a linear
model are statistically significant.</p>

<h1 id="hypothesis-testing-in-linear-regression">Hypothesis testing in linear regression</h1>

<p>Using the linear model we defined above, we can ask questions based on the 
estimated value for the regression coefficients. For example, do individuals
with different age have different methylation values for a given CpG? We usually 
do this via <em>hypothesis testing</em>. This framework compares the results that we 
observed (here, estimated linear model coefficients) to the results you would 
expect under a <em>null hypothesis</em> associated to our question. In the example above, 
a suitable null hypothesis would test whether the regression coefficient associated
to age ($\beta_1$) is equal to zero or not. If $\beta_1$ is equal to zero,
the linear model indicates that there is no linear relationship between age
and the methylation level for the CpG  (remember: as its name suggests, linear 
regression can only be used to model linear relationships between predictors and 
outcomes!). In other words, the answer to our question would be: no!</p>

<p>The output of a linear model typically returns the results associated 
with the null hypothesis described above (this may not always be the most realistic 
or useful null hypothesis, but it is the one we have by default!). To be 
more specific, the test compares our observed results with a set of 
hypothetical counter-examples of what we would expect to observe if we repeated 
the same experiment and analysis over and over again under the null hypothesis.</p>

<p>For this linear model, we can use <code class="language-plaintext highlighter-rouge">tidy()</code> from the <strong><code class="language-plaintext highlighter-rouge">broom</code></strong> package to 
extract detailed information about the coefficients and the associated 
hypothesis tests in this model:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="s2">"broom"</span><span class="p">)</span><span class="w">
</span><span class="n">tidy</span><span class="p">(</span><span class="n">lm_age_methyl1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code># A tibble: 2 × 5
  term        estimate std.error statistic p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 (Intercept)  0.902      0.344      2.62   0.0129
2 age          0.00891    0.0100     0.888  0.381 
</code></pre></div></div>

<p>The standard errors (<code class="language-plaintext highlighter-rouge">std.error</code>) represent the statistical uncertainty in our
regression coefficient estimates (often referred to as <em>effect size</em>). The test 
statistics and p-values represent measures of how (un)likely it would be to observe 
results like this under the “null hypothesis”.</p>

<blockquote class="challenge">
  <h2 id="challenge-2">Challenge 2</h2>

  <p>In the model we fitted, the estimate for the intercept is 0.902 and its associated 
p-value is 0.0129. What does this mean?</p>

  <blockquote class="solution">
    <h2 id="solution-1">Solution</h2>

    <p>The first coefficient in a linear model like this is the intercept, which measures 
the mean of the outcome (in this case, the methylation value for the first CpG)
when age is zero. In this case, the intercept estimate is 0.902. However, this is 
not a particularly noteworthy finding as we do not have any observations with age
zero (nor even any with age &lt; 20!).</p>

    <p>The reported p-value is associated to the following null hypothesis:
the intercept ($\beta_0$ above) is equal to zero. Using the usual
significance threshold of 0.05, we reject the null hypothesis as
the p-value is smaller than 0.05. However, it is not really interesting
if this intercept is zero or not, since we probably do not care what the
methylation level is when age is zero. In fact, this question does not
even make much sense! In this example, we are more interested
in the regression coefficient associated to age, as that can tell us 
whether there is a linear relationship between age and methylation for the CpG.</p>

  </blockquote>
</blockquote>

<h1 id="fitting-a-lot-of-linear-models">Fitting a lot of linear models</h1>

<p>In the linear model above, we are generally interested in the second regression
coefficient (often referred to as <em>slope</em>) which measures the linear relationship
between age and methylation levels. For the first CpG, here is its estimate:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">coef_age_methyl1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tidy</span><span class="p">(</span><span class="n">lm_age_methyl1</span><span class="p">)[</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w">
</span><span class="n">coef_age_methyl1</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code># A tibble: 1 × 5
  term  estimate std.error statistic p.value
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 age    0.00891    0.0100     0.888   0.381
</code></pre></div></div>

<p>In this case, the p-value is equal to 0.381 and therefore we cannot reject the null
hypothesis: there is no statistical evidence to suggest that the regression 
coefficient associated to age is not equal to zero.</p>

<p>Now, we could do this for every feature (CpG) in the dataset and rank the
results based on their test statistic or associated p-value. However, fitting
models in this way to 5000 features is not very computationally 
efficient, and it would also be laborious to do programmatically. There are ways 
to get around this, but first let us talk about what exactly we are doing when 
we look at significance tests in this context.</p>

<h1 id="how-does-hypothesis-testing-for-a-linear-model-work">How does hypothesis testing for a linear model work?</h1>

<p>In order to decide whether a result would be unlikely under the null
hypothesis, we must calculate a test statistic. For coefficient $k$ in a
linear model (in our case, it would be the slope), the test statistic is
a t-statistic given by:</p>

\[t_{k} = \frac{\hat{\beta}_{k}}{SE\left(\hat{\beta}_{k}\right)}\]

<p>$SE\left(\hat{\beta}_{k}\right)$ measures the uncertainty we have in our
effect size estimate. Knowing what distribution these t-statistics
follow under the null hypothesis allows us to determine how unlikely it
would be for us to observe what we have under those circumstances, if we
repeated the experiment and analysis over and over again. To
demonstrate, we can compute the t-statistics “by hand” (advanced content).</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">table_age_methyl1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tidy</span><span class="p">(</span><span class="n">lm_age_methyl1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>We can see that the t-statistic is just the ratio between the coefficient estimate
and the standard error:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tvals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">table_age_methyl1</span><span class="o">$</span><span class="n">estimate</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">table_age_methyl1</span><span class="o">$</span><span class="n">std.error</span><span class="w">
</span><span class="n">all.equal</span><span class="p">(</span><span class="n">tvals</span><span class="p">,</span><span class="w"> </span><span class="n">table_age_methyl1</span><span class="o">$</span><span class="n">statistic</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1] TRUE
</code></pre></div></div>

<p>Calculating the p-values is a bit more tricky. Specifically, it is the
proportion of the distribution of the test statistic under the null
hypothesis that is <em>as extreme or more extreme</em> than the observed value
of the test statistic. This is easy to observe visually, by plotting the
theoretical distribution of the test statistic under the null hypothesis 
(see next call-out box for more details about it):</p>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-tdist-1.png" alt="Density plot of a t-distribution showing the observed test statistics (here, t-statistics). The p-values, visualised here with shaded regions, represent the portion of the null distribution that is as extreme or more extreme as the observed test statistics, which are shown as dashed lines." width="432" />
<p class="caption">The p-value for a regression coefficient represents how often it'd be observed under the null.</p>
</div>

<p>The red-ish shaded region represents the portion of the distribution of
the test statistic under the null hypothesis that is equal or greater to
the value we observe for the intercept term. As our null hypothesis 
relates to a 2-tailed test (as the null hypothesis states that the regression
coefficient is equal to zero, we would reject it if the regression
coefficient is substantially larger <strong>or</strong> smaller than zero), the p-value for
the test is twice the value of the shaded region. In this case, the shaded region 
is small relative to the total area of the null distribution; therefore, the
p-value is small ($p=0.013$). The blue-ish shaded region represents the same measure for the slope term; 
this is larger, relative to the total area of the distribution, therefore the 
p-value is larger than the one for the intercept term 
($p=0.381$). The
the p-value is a function of the test statistic: the ratio between the effect size 
we’re estimating and the uncertainty we have in that effect. A large effect with large
uncertainty may not lead to a small p-value, and a small effect with
small uncertainty may lead to a small p-value.</p>

<blockquote class="callout">
  <h2 id="calculating-p-values-from-a-linear-model">Calculating p-values from a linear model</h2>

  <p>Manually calculating the p-value for a linear model is a little bit
more complex than calculating the t-statistic. The intuition posted
above is definitely sufficient for most cases, but for completeness,
here is how we do it:</p>

  <p>Since the statistic in a linear model is a t-statistic, it follows a
student t distribution under the null hypothesis, with degrees of
freedom (a parameter of the student t-distribution) given by the
number of observations minus the number of coefficients fitted, in
this case
$37 - 2 = 35$.
We want to know what portion of the distribution function of the test
statistic is as extreme as, or more  extreme than, the value we observed.
The function<code class="language-plaintext highlighter-rouge">pt()</code>(similar to<code class="language-plaintext highlighter-rouge">pnorm()</code>, etc) can give us this information.</p>

  <p>Since we’re not sure if the coefficient will be larger or smaller than
zero, we want to do a 2-tailed test. Therefore we take the absolute
value of the t-statistic, and look at the upper rather than lower
tail. In the figure above the shaded areas are only looking at “half” of the
t-distribution (which is symmetric around zero), therefore we multiply the 
shaded area by 2 in order to calculate the p-value.</p>

  <p>Combining all of this gives us:</p>

  <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pvals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">pt</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">tvals</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm_age_methyl1</span><span class="o">$</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">all.equal</span><span class="p">(</span><span class="n">table_age_methyl1</span><span class="o">$</span><span class="n">p.value</span><span class="p">,</span><span class="w"> </span><span class="n">pvals</span><span class="p">)</span><span class="w">
</span></code></pre></div>  </div>

  <div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1] TRUE
</code></pre></div>  </div>
</blockquote>

<h1 id="sharing-information-across-outcome-variables">Sharing information across outcome variables</h1>

<p>Now that we understand how hypothesis tests work in the 
linear model framework, we are going to introduce an idea that allows us to
take advantage of the fact that we carry out many tests at once on
structured data. We can leverage this fact to <em>share information</em>
between model parameters. The insight that we use to perform
<em>information pooling</em> or sharing is derived from our knowledge about the
structure of the data. For example, in a high-throughput experiment like
a DNA methylation assay, we know that all of the features were measured
simultaneously, using the same technique. This means that generally, we
expect the base-level variability for each feature to be broadly
similar.</p>

<p>This can enable us to get a better estimate of the uncertainty of model
parameters than we could get if we consider each feature in isolation.
So, to share information between features allows us to get more robust
estimators. Remember that the t-statistic for coefficient $\beta_k$ in a
linear model is the ratio between the coefficient estimate and its standard
error:</p>

\[t_{k} = \frac{\hat{\beta}_{k}}{SE\left(\hat{\beta}_{k}\right)}\]

<p>It is clear that large effect sizes will likely lead to small p-values,
as long as the standard error for the coefficent is not large. However,
the standard error is affected by the amount of noise, as we saw
earlier. If we have a small number of observations, it is common for the
noise for some features to be extremely small simply by chance. This, in turn,
causes small p-values for these features, which may give us unwarranted
confidence in the level of certainty we have in the results (false positives).</p>

<p>There are many statistical methods in genomics that use this type of
approach to get better estimates by pooling information between features
that were measured simultaneously using the same techniques. Here we
will focus on the package <strong><code class="language-plaintext highlighter-rouge">limma</code></strong>, which is an established software
package used to fit linear models, originally for the gene expression
micro-arrays that were common in the 2000s, but which is still in use in
RNAseq experiments, among others. The authors of <strong><code class="language-plaintext highlighter-rouge">limma</code></strong> made some
assumptions about the distributions that these follow, and pool
information across genes to get a better estimate of the uncertainty in
effect size estimates. It uses the idea that noise levels should be
similar between features to <em>moderate</em> the estimates of the test
statistic by shrinking the estimates of standard errors towards a common
value. This results in a <em>moderated t-statistic</em>.</p>

<p>The process of running a model in <strong><code class="language-plaintext highlighter-rouge">limma</code></strong> is somewhat different to what you
may have seen when running linear models. Here, we define a <em>model matrix</em> or 
<em>design matrix</em>, which is a way of representing the
coefficients that should be fit in each linear model. These are used in
similar ways in many different modelling libraries.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="s2">"limma"</span><span class="p">)</span><span class="w">
</span><span class="n">design_age</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">age</span><span class="p">)</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">design_age</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1] 37  2
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">head</span><span class="p">(</span><span class="n">design_age</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  (Intercept) age
1           1  39
2           1  49
3           1  20
4           1  49
5           1  33
6           1  21
</code></pre></div></div>

<blockquote class="callout">
  <h2 id="what-is-a-model-matrix">What is a model matrix?</h2>
  <p>When R fits a regression model, it chooses a vector of regression coefficients 
that minimises the differences between outcome values and those values 
predicted by using the covariates (or predictor variables). But how do we get 
from a set of predictors and regression coefficients to predicted values? This 
is done via matrix multipliciation. The matrix of predictors is (matrix) 
multiplied by the vector of coefficients. That matrix is called the 
<strong>model matrix</strong> (or design matrix). It has one row for each observation and 
one column for each predictor plus (by default) one aditional column of ones 
(the intercept column). Many R libraries (but not <strong><code class="language-plaintext highlighter-rouge">limma</code></strong> ) contruct the 
model matrix behind the scenes. Usually, it can be extracted from a model fit 
using the function <code class="language-plaintext highlighter-rouge">model.matrix()</code>. Here is an example:</p>

  <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">(</span><span class="n">cars</span><span class="p">)</span><span class="w">
</span><span class="n">head</span><span class="p">(</span><span class="n">cars</span><span class="p">)</span><span class="w">
</span></code></pre></div>  </div>

  <div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  speed dist
1     4    2
2     4   10
3     7    4
4     7   22
5     8   16
6     9   10
</code></pre></div>  </div>

  <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mod1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">dist</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">speed</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">cars</span><span class="p">)</span><span class="w"> </span><span class="c1"># fit regression model using speed as a predictor</span><span class="w">
</span><span class="n">head</span><span class="p">(</span><span class="n">model.matrix</span><span class="p">(</span><span class="n">mod1</span><span class="p">))</span><span class="w"> </span><span class="c1"># the model matrix contains two columns: intercept and speed</span><span class="w">
</span></code></pre></div>  </div>

  <div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  (Intercept) speed
1           1     4
2           1     4
3           1     7
4           1     7
5           1     8
6           1     9
</code></pre></div>  </div>
</blockquote>

<p>As you can see, the design matrix has the same number of rows as our
methylation data has samples. It also has two columns - one for the
intercept (similar to the linear model we fit above) and one for age.
This happens “under the hood” when fitting a linear model with <code class="language-plaintext highlighter-rouge">lm()</code>, but
here we have to specify it directly. The <a href="https://www.bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf">limma user
manual</a>
has more detail on how to make design matrices for different types of
experimental design, but here we are going to stick with this simple two-variable case.</p>

<p>We then pass our matrix of methylation values into <code class="language-plaintext highlighter-rouge">lmFit()</code>, specifying
the design matrix. Internally, this function runs <code class="language-plaintext highlighter-rouge">lm()</code> on each row of
the data in an efficient way. The function <code class="language-plaintext highlighter-rouge">eBayes()</code>, when applied to the
output of <code class="language-plaintext highlighter-rouge">lmFit()</code>, performs the pooled estimation of standard errors
that results in the moderated t-statistics and resulting p-values.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fit_age</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">methyl_mat</span><span class="p">,</span><span class="w"> </span><span class="n">design</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">design_age</span><span class="p">)</span><span class="w">
</span><span class="n">fit_age</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_age</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>To obtain the results of the linear models, we can use the <code class="language-plaintext highlighter-rouge">topTable()</code>
function. By default, this returns results for the first coefficient in
the model. As we saw above when using <code class="language-plaintext highlighter-rouge">lm()</code>, and when we defined
<code class="language-plaintext highlighter-rouge">design_age</code> above, the first coefficient relates to the intercept term,
which we are not particularly interested in here; therefore we specify
<code class="language-plaintext highlighter-rouge">coef = 2</code>. Further, <code class="language-plaintext highlighter-rouge">topTable()</code> by default only returns the top 10
results. To see all of the results in the data, we specify
<code class="language-plaintext highlighter-rouge">number = nrow(fit_age)</code> to ensure that it returns a row for every row
of the input matrix.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">toptab_age</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_age</span><span class="p">,</span><span class="w"> </span><span class="n">coef</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">fit_age</span><span class="p">))</span><span class="w">
</span><span class="n">orderEffSize</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rev</span><span class="p">(</span><span class="n">order</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">toptab_age</span><span class="o">$</span><span class="n">logFC</span><span class="p">)))</span><span class="w"> </span><span class="c1"># order by effect size (absolute log-fold change)</span><span class="w">
</span><span class="n">head</span><span class="p">(</span><span class="n">toptab_age</span><span class="p">[</span><span class="n">orderEffSize</span><span class="p">,</span><span class="w"> </span><span class="p">])</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                 logFC    AveExpr         t    P.Value adj.P.Val         B
cg22160073 -0.07615967  0.2261869 -2.200534 0.03410063 0.2563957 -5.536033
cg02371766 -0.07480442  1.6744282 -2.032526 0.04933710 0.3004092 -5.861179
cg18633711 -0.07221177 -0.1668962 -2.254569 0.03017881 0.2459313 -5.427228
cg01267675 -0.06393861  1.2496114 -2.127641 0.04010694 0.2758387 -5.679584
cg07334644 -0.05880317  0.9591176 -2.297448 0.02735916 0.2339981 -5.339467
cg01387455 -0.05873510  0.5872700 -2.051339 0.04737637 0.2964936 -5.825782
</code></pre></div></div>

<p>The output of <code class="language-plaintext highlighter-rouge">topTable</code> includes the coefficient, here termed a log
fold change <code class="language-plaintext highlighter-rouge">logFC</code>, the average level (<code class="language-plaintext highlighter-rouge">aveExpr</code>), the t-statistic <code class="language-plaintext highlighter-rouge">t</code>,
the p-value (<code class="language-plaintext highlighter-rouge">P.Value</code>), and the <em>adjusted</em> p-value (<code class="language-plaintext highlighter-rouge">adj.P.Val</code>). We’ll
cover what an adjusted p-value is very shortly. The table also includes
<code class="language-plaintext highlighter-rouge">B</code>, which represents the log-odds that a feature is signficantly
different, which we won’t cover here, but which will generally be a 1-1
transformation of the p-value. The coefficient estimates here are termed
<code class="language-plaintext highlighter-rouge">logFC</code> for legacy reasons relating to how microarray experiments were
traditionally performed. There are more details on this topic in many
places, for example <a href="https://kasperdanielhansen.github.io/genbioconductor/html/limma.html">this tutorial by Kasper D.
Hansen</a></p>

<p>Now we have estimates of effect sizes and p-values for the association
between methylation level at each locus and age for our 37 samples. It’s
useful to create a plot of effect size estimates (model coefficients)
against p-values for each of these linear models, to visualise the
magnitude of effects and the statistical significance of each. These
plots are often called “volcano plots”, because they resemble an
eruption.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">toptab_age</span><span class="o">$</span><span class="n">logFC</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="n">log10</span><span class="p">(</span><span class="n">toptab_age</span><span class="o">$</span><span class="n">P.Value</span><span class="p">),</span><span class="w">
    </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Effect size"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bquote</span><span class="p">(</span><span class="o">-</span><span class="n">log</span><span class="p">[</span><span class="m">10</span><span class="p">](</span><span class="n">p</span><span class="o">-</span><span class="n">value</span><span class="p">)),</span><span class="w">
    </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">19</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-limmavolc1-1.png" alt="A plot of -log10(p) against effect size estimates for a regression of age against methylation using limma." width="432" />
<p class="caption">Plotting p-values against effect sizes using limma; the results are similar to a standard linear model.</p>
</div>

<p>In this figure, every point represents a feature of interest. The x-axis
represents the effect size observed for that feature in a linear model,
while the y-axis is the $-\log_{10}(\text{p-value})$, where larger
values indicate increasing statistical evidence of a non-zero effect
size. A positive effect size represents increasing methylation with
increasing age, and a negative effect size represents decreasing
methylation with increasing age. Points higher on the x-axis represent
features for which we think the results we observed would be very
unlikely under the null hypothesis.</p>

<p>Since we want to identify features that have different methylation levels
in different age groups, in an ideal case there would be clear
separation between “null” and “non-null” features. However, usually we
observe results as we do here: there is a continuum of effect sizes and
p-values, with no clear separation between these two classes of
features. While statistical methods exist to derive insights from
continuous measures like these, it is often convenient to obtain a list
of features which we are confident have non-zero effect sizes. This is
made more difficult by the number of tests we perform.</p>

<blockquote class="challenge">
  <h2 id="challenge-3">Challenge 3</h2>

  <p>The effect size estimates are very small, and yet many of the p-values
are well below a usual significance level of p &lt; 0.05. Why is this?</p>

  <blockquote class="solution">
    <h2 id="solution-2">Solution</h2>

    <p>Because age has a much larger range than methylation levels, the
unit change in methylation level even for a strong relationship is
very small!</p>

    <p>As we mentioned, the p-value is a function of both the effect size
estimate and the uncertainty (standard error) of that estimate.
Because the uncertainty in our estimates is much smaller than the
estimates themselves, the p-values are also small.</p>

    <p>If we predicted age using methylation level, it is likely we would see
much larger coefficients, though broadly similar p-values!</p>

  </blockquote>
</blockquote>

<p>It is worthwhile considering what exactly the effect of the <em>moderation</em>
or information sharing that <strong><code class="language-plaintext highlighter-rouge">limma</code></strong> performs has on our results. To do
this, let us compare the effect sizes estimates and p-values from the two
approaches.</p>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-plot-limma-lm-effect-1.png" alt="plot of chunk plot-limma-lm-effect" width="432" />
<p class="caption">plot of chunk plot-limma-lm-effect</p>
</div>

<p>These are exactly identical! This is because <strong><code class="language-plaintext highlighter-rouge">limma</code></strong> does not perform
any sharing of information when estimating effect sizes. This is in
contrast to similar packages that apply shrinkage to the effect size
estimates, like <strong><code class="language-plaintext highlighter-rouge">DESeq2</code></strong>. These often use information sharing to shrink
or moderate the effect size estimates, in the case of <strong><code class="language-plaintext highlighter-rouge">DESeq2</code></strong> by again
sharing information between features about sample-to-sample variability.
In contrast, let us look at the p-values from <strong><code class="language-plaintext highlighter-rouge">limma</code></strong> and R’s built-in <code class="language-plaintext highlighter-rouge">lm()</code> function:</p>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-plot-limma-lm-pval-1.png" alt="plot of chunk plot-limma-lm-pval" width="432" />
<p class="caption">plot of chunk plot-limma-lm-pval</p>
</div>

<p>we can see that for the vast majority of features, the results are
broadly similar. There seems to be a minor general tendency for <strong><code class="language-plaintext highlighter-rouge">limma</code></strong>
to produce smaller p-values, but for several features, the p-values from
limma are considerably larger than the p-values from <code class="language-plaintext highlighter-rouge">lm()</code>. This is
because the information sharing tends to shrink large standard error
estimates downwards and small estimates upwards. When the degree of
statistical significance is due to an abnormally small standard error
rather than a large effect, this effect results in this prominent
reduction in statistical significance, which has been shown to perform
well in case studies. The degree of shrinkage generally depends on the
amount of pooled information and the strength of the evidence
independent of pooling. For example, with very few samples and many
features, information sharing has a larger effect, because there are a
lot of genes that can be used to provide pooled estimates, and the
evidence from the data that this is weighed against is relatively
sparse. In contrast, when there are many samples and few features, there
is not much opportunity to generate pooled estimates, and the evidence
of the data can easily outweigh the pooling.</p>

<p>Shrinkage methods like these ones can be complex to implement and
understand, but it is useful to develop an intuition about why these approaches may be more
precise and sensitive than the naive approach of fitting a model to each
feature separately.</p>

<blockquote class="challenge">
  <h2 id="challenge-4">Challenge 4</h2>

  <ol>
    <li>Try to run the same kind of linear model with smoking status as
covariate instead of age, and making a volcano plot. <em>Note:
smoking status is stored as</em> <code class="language-plaintext highlighter-rouge">methylation$smoker</code>.</li>
    <li>We saw in the example in the lesson that this information sharing
can lead to larger p-values. Why might this be preferable?</li>
  </ol>

  <blockquote class="solution">
    <h2 id="solution-3">Solution</h2>

    <ol>
      <li>
        <p>The following code runs the same type of model with smoking
status:</p>

        <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">design_smoke</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">methylation</span><span class="o">$</span><span class="n">smoker</span><span class="p">)</span><span class="w">
</span><span class="n">fit_smoke</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">methyl_mat</span><span class="p">,</span><span class="w"> </span><span class="n">design</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">design_smoke</span><span class="p">)</span><span class="w">
</span><span class="n">fit_smoke</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_smoke</span><span class="p">)</span><span class="w">
</span><span class="n">toptab_smoke</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_smoke</span><span class="p">,</span><span class="w"> </span><span class="n">coef</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">fit_smoke</span><span class="p">))</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">toptab_smoke</span><span class="o">$</span><span class="n">logFC</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="n">log10</span><span class="p">(</span><span class="n">toptab_smoke</span><span class="o">$</span><span class="n">P.Value</span><span class="p">),</span><span class="w">
    </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Effect size"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bquote</span><span class="p">(</span><span class="o">-</span><span class="n">log</span><span class="p">[</span><span class="m">10</span><span class="p">](</span><span class="n">p</span><span class="p">)),</span><span class="w">
    </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">19</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div>        </div>

        <div class="figure" style="text-align: center">
<img src="../fig/rmd-02-limmavolc2-1.png" alt="A plot of -log10(p) against effect size estimates for a regression of smoking status against methylation using limma." width="432" />
<p class="caption">A plot of significance against effect size for a regression of smoking against methylation.</p>
</div>
      </li>
      <li>
        <p>Being a bit more conservative when identifying features can help
to avoid false discoveries. Furthermore, when rejecting the null
hypothesis is based more on a small standard error resulting
from abnormally low levels of variability for a given feature,
we might want to be a bit more conservative in our expectations.</p>
      </li>
    </ol>
  </blockquote>
</blockquote>

<blockquote class="callout">
  <h2 id="shrinkage">Shrinkage</h2>

  <p>Shrinkage is an intuitive term for an effect of information sharing,
and is something observed in a broad range of statistical models.
Often, shrinkage is induced by a <em>multilevel</em> modelling approach or by
<em>Bayesian</em> methods.</p>

  <p>The general idea is that these models incorporate information about
the structure of the data into account when fitting the parameters. We
can share information between features because of our knowledge about
the data structure; this generally requires careful consideration
about how the data were generated and the relationships within.</p>

  <p>An example people often use is estimating the effect of attendance on
grades in several schools. We can assume that this effect is similar
in different schools (but maybe not identical), so we can <em>share
information</em> about the effect size between schools and shrink our
estimates towards a common value.</p>

  <p>For example in <strong><code class="language-plaintext highlighter-rouge">DESeq2</code></strong>, the authors used the observation that genes
with similar expression counts in RNAseq data have similar
<em>dispersion</em>, and a better estimate of these dispersion parameters
makes estimates of fold changes much more stable. Similarly, in
<strong><code class="language-plaintext highlighter-rouge">limma</code></strong> the authors made the assumption that in the absence of
biological effects, we can often expect the technical variation in the
measurement of the expression of each of the genes to be broadly
similar. Again, better estimates of variability allow us to prioritise
genes in a more reliable way.</p>

  <p>There are many good resources to learn about this type of approach,
including:</p>

  <ul>
    <li><a href="https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/">a blog post by TJ
Mahr</a></li>
    <li><a href="https://gumroad.com/l/empirical-bayes">a book by David Robinson</a></li>
    <li><a href="http://www.stat.columbia.edu/~gelman/arm/">a (relatively technical) book by Gelman and
Hill</a></li>
  </ul>
</blockquote>

<h1 id="the-problem-of-multiple-tests">The problem of multiple tests</h1>

<p>With such a large number of features, it would be useful to decide which
features are “interesting” or “significant” for further study. However,
if we were to apply a normal significance threshold of 0.05, it would be likely
we end up with a lot of false positives. This is because a p-value
threshold like this represents a $\frac{1}{20}$ chance that we observe
results as extreme or more extreme under the null hypothesis (that there
is no assocation between age and methylation level). If we carry out many more
than 20 such tests, we can expect to see situations where, despite the null
hypothesis being true, we observe observe signifiant p-values due to random chance. To
demonstrate this, it is useful to see what happens if we permute (scramble) the age values and
run the same test again:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">age_perm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">age</span><span class="p">[</span><span class="n">sample</span><span class="p">(</span><span class="n">ncol</span><span class="p">(</span><span class="n">methyl_mat</span><span class="p">),</span><span class="w"> </span><span class="n">ncol</span><span class="p">(</span><span class="n">methyl_mat</span><span class="p">))]</span><span class="w">
</span><span class="n">design_age_perm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">age_perm</span><span class="p">)</span><span class="w">

</span><span class="n">fit_age_perm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">methyl_mat</span><span class="p">,</span><span class="w"> </span><span class="n">design</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">design_age_perm</span><span class="p">)</span><span class="w">
</span><span class="n">fit_age_perm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_age_perm</span><span class="p">)</span><span class="w">
</span><span class="n">toptab_age_perm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_age_perm</span><span class="p">,</span><span class="w"> </span><span class="n">coef</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">fit_age_perm</span><span class="p">))</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">toptab_age_perm</span><span class="o">$</span><span class="n">logFC</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="n">log10</span><span class="p">(</span><span class="n">toptab_age_perm</span><span class="o">$</span><span class="n">P.Value</span><span class="p">),</span><span class="w">
    </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Effect size"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bquote</span><span class="p">(</span><span class="o">-</span><span class="n">log</span><span class="p">[</span><span class="m">10</span><span class="p">](</span><span class="n">p</span><span class="p">)),</span><span class="w">
    </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">19</span><span class="w">
</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="n">log10</span><span class="p">(</span><span class="m">0.05</span><span class="p">),</span><span class="w"> </span><span class="n">lty</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-volcplotfake-1.png" alt="Plot of -log10(p) against effect size estimates for a regression of a made-up feature against methylation level for each feature in the data. A dashed line represents a 0.05 significance level." width="432" />
<p class="caption">Plotting p-values against effect sizes for a randomised outcome shows we still observe 'significant' results.</p>
</div>

<p>Since we have generated a random sequence of ages, we have no reason to
suspect that there is a true association between methylation levels and
this sequence of random numbers. However, you can see that the p-value
for many features is still lower than a traditional significance level
of $p=0.05$. In fact, here 235
features are significant at p &lt; 0.05. If we were to use this fixed
threshold in a real experiment, it is likely that we would identify many
features as associated with age, when the results we are observing are
simply due to chance.</p>

<blockquote class="challenge">
  <h2 id="challenge-5">Challenge 5</h2>

  <ol>
    <li>If we run 5000 tests under the null hypothesis,
how many of them (on average) will be statistically significant at
a threshold of $p &lt; 0.05$?</li>
    <li>Why would we want to be conservative in labelling features as
significantly different? By conservative, we mean to err towards
labelling true differences as “not significant” rather than vice
versa.</li>
    <li>How could we account for a varying number of tests to ensure
“significant” changes are truly different?</li>
  </ol>

  <blockquote class="solution">
    <h2 id="solution-4">Solution</h2>

    <ol>
      <li>By default we expect
$5000 \times 0.05 = 250$
features to be statistically significant under the null
hypothesis, because p-values should always be uniformly
distributed under the null hypothesis.</li>
      <li>Features that we label as “significantly different” will often
be reported in manuscripts. We may also spend time and money
investigating them further, computationally or in the lab.
Therefore, spurious results have a real cost for ourselves and
for others.</li>
      <li>One approach to controlling for the number of tests is to divide
our significance threshold by the number of tests performed.
This is termed “Bonferroni correction” and we’ll discuss this
further now.</li>
    </ol>
  </blockquote>
</blockquote>

<h1 id="adjusting-for-multiple-tests">Adjusting for multiple tests</h1>

<p>When performing many statistical tests to categorise features, we are
effectively classifying features as “non-significant” or “significant”, that latter meaning those for
which we reject the null hypothesis. We also
generally hope that there is a subset of features for which the null
hypothesis is truly false, as well as many for which the null truly does
hold. We hope that for all features for which the null hypothesis is
true, we accept it, and for all features for which the null hypothesis
is not true, we reject it. As we showed in the example with permuted
age, with a large number of tests it is inevitable that we will get some of
these wrong.</p>

<p>We can think of these features as being “truly different” or “not truly
different”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. Using this idea, we can see that each categorisation we
make falls into four categories:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: right">Label as different</th>
      <th style="text-align: right">Label as not different</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">Truly different</td>
      <td style="text-align: right">True positive</td>
      <td style="text-align: right">False negative</td>
    </tr>
    <tr>
      <td style="text-align: right">Truly not different</td>
      <td style="text-align: right">False positive</td>
      <td style="text-align: right">True negative</td>
    </tr>
  </tbody>
</table>

<p>If the null hypothesis was true for every feature, then as we perform
more and more tests we’d tend to correctly categorise most results as
negative. However, since p-values are uniformly distributed under the
null, at a significance level of 5%, 5% of all results will be
“significant” even though we would expect to see these results, given
the null hypothesis is true, simply by chance. These would fall under
the label “false positives” in the table above, and are also termed
“false discoveries.”</p>

<p>There are two common ways of controlling these false discoveries. The
first is to say, when we’re doing $n$ tests, that we want to have the
same certainty of making one false discovery with $n$ tests as we have
if we’re only doing one test. This is “Bonferroni” correction,<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> which
divides the significance level by the number of tests performed, $n$.
Equivalently, we can use the non-transformed p-value threshold but
multiply our p-values by the number of tests. This is often very
conservative, especially with a lot of features!</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_raw</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">toptab_age</span><span class="o">$</span><span class="n">P.Value</span><span class="w">
</span><span class="n">p_fwer</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">p.adjust</span><span class="p">(</span><span class="n">p_raw</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"bonferroni"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"ggplot2"</span><span class="p">)</span><span class="w">
</span><span class="n">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">aes</span><span class="p">(</span><span class="n">p_raw</span><span class="p">,</span><span class="w"> </span><span class="n">p_fwer</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">scale_y_log10</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Raw p-value"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Bonferroni p-value"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="figure" style="text-align: center">
<img src="../fig/rmd-02-p-fwer-1.png" alt="Plot of Bonferroni-adjusted p-values (y) against unadjusted p-values (x). A dashed black line represents the identity (where x=y), while dashed red lines represent 0.05 significance thresholds." width="432" />
<p class="caption">Bonferroni correction often produces very large p-values, especially with low sample sizes.</p>
</div>

<p>You can see that the p-values are exactly one for the vast majority of
tests we performed! This is not ideal sometimes, because unfortunately
we usually don’t have very large sample sizes in health sciences.</p>

<p>The second main way of controlling for multiple tests is to control the
<em>false discovery rate</em>.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> This is the proportion of false positives,
or false discoveries, we’d expect to get each time if we repeated the
experiment over and over.</p>

<ol>
  <li>Rank the p-values</li>
  <li>Assign each a rank (1 is smallest)</li>
  <li>Calculate the critical value \(q = \left(\frac{i}{m}\right)Q\), where $i$ is rank, $m$ is the number of tests, and $Q$ is the
false discovery rate we want to target.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup></li>
  <li>Find the largest p-value less than the critical value. All smaller
than this are significant.</li>
</ol>

<table>
  <thead>
    <tr>
      <th style="text-align: left">FWER</th>
      <th style="text-align: left">FDR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">+ Controls probability of identifying a false positive</td>
      <td style="text-align: left">+ Controls rate of false discoveries</td>
    </tr>
    <tr>
      <td style="text-align: left">+ Strict error rate control</td>
      <td style="text-align: left">+ Allows error control with less stringency</td>
    </tr>
    <tr>
      <td style="text-align: left">- Very conservative</td>
      <td style="text-align: left">- Does not control probability of making errors</td>
    </tr>
    <tr>
      <td style="text-align: left">- Requires larger statistical power</td>
      <td style="text-align: left">- May result in false discoveries</td>
    </tr>
  </tbody>
</table>

<blockquote class="challenge">
  <h2 id="challenge-6">Challenge 6</h2>

  <ol>
    <li>At a significance level of 0.05, with 100 tests performed, what is
the Bonferroni significance threshold?</li>
    <li>In a gene expression experiment, after FDR correction we observe
500 significant genes. What proportion of these genes are truly
different?</li>
    <li>Try running FDR correction on the <code class="language-plaintext highlighter-rouge">p_raw</code> vector. <em>Hint: check
<code class="language-plaintext highlighter-rouge">help("p.adjust")</code> to see what the method is called</em>.<br />
Compare these values to the raw p-values and the Bonferroni
p-values.</li>
  </ol>

  <blockquote class="solution">
    <h2 id="solution-5">Solution</h2>

    <ol>
      <li>
        <p>The Bonferroni threshold for this significance threshold is \(\frac{0.05}{100} = 0.0005\)</p>
      </li>
      <li>
        <p>Trick question! We can’t say what proportion of these genes are
truly different. However, if we repeated this experiment and
statistical test over and over, on average 5% of the results
from each run would be false discoveries.</p>
      </li>
      <li>
        <p>The following code runs FDR correction and compares it to
non-corrected values and to Bonferroni:</p>

        <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_fdr</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">p.adjust</span><span class="p">(</span><span class="n">p_raw</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BH"</span><span class="p">)</span><span class="w">
</span><span class="n">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">aes</span><span class="p">(</span><span class="n">p_raw</span><span class="p">,</span><span class="w"> </span><span class="n">p_fdr</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">scale_y_log10</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Raw p-value"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Benjamini-Hochberg p-value"</span><span class="p">)</span><span class="w">
</span></code></pre></div>        </div>

        <div class="figure" style="text-align: center">
<img src="../fig/rmd-02-p-fdr-1.png" alt="Plot of Benjamini-Hochberg-adjusted p-values (y) against unadjusted p-values (x). A dashed black line represents the identity (where x=y), while dashed red lines represent 0.05 significance thresholds." width="432" />
<p class="caption">Benjamini-Hochberg correction is less conservative than Bonferroni</p>
</div>

        <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">aes</span><span class="p">(</span><span class="n">p_fdr</span><span class="p">,</span><span class="w"> </span><span class="n">p_fwer</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">scale_y_log10</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Benjamini-Hochberg p-value"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Bonferroni p-value"</span><span class="p">)</span><span class="w">
</span></code></pre></div>        </div>

        <div class="figure" style="text-align: center">
<img src="../fig/rmd-02-plot-fdr-fwer-1.png" alt="Plot of Benjamini-Hochberg-adjusted p-values (y) against Bonferroni-adjusted p-values (x). A dashed black line represents the identity (where x=y), while dashed red lines represent 0.05 significance thresholds." width="432" />
<p class="caption">plot of chunk plot-fdr-fwer</p>
</div>
      </li>
    </ol>

  </blockquote>
</blockquote>

<blockquote class="callout">
  <h2 id="feature-selection">Feature selection</h2>

  <p>In this episode, we have focussed on regression in a setting where there are more
features than observations. This approach is relevant if we are interested in the
association of each feature with some outcome or if we want to screen for features
that have a strong association with an outcome. If, however, we are interested in
predicting an outcome or if we want to know which features explain the variation
in the outcome, we may want to restrict ourselves to a subset of relevant features.
One way of doing this is called <em>regularisation</em>, and this is the topic of the next episode.
An alternative is called <em>feature selection</em>. This is covered in the subsequent (optional) episode.</p>
</blockquote>

<h2 id="further-reading">Further reading</h2>

<ul>
  <li><a href="https://kasperdanielhansen.github.io/genbioconductor/html/limma.html"><strong><code class="language-plaintext highlighter-rouge">limma</code></strong> tutorial by Kasper D.
Hansen</a></li>
  <li><a href="https://www.bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf"><strong><code class="language-plaintext highlighter-rouge">limma</code></strong> user
manual</a>.</li>
  <li><a href="https://bioconductor.org/packages/release/bioc/vignettes/variancePartition/inst/doc/dream.html">The <strong><code class="language-plaintext highlighter-rouge">VariancePartition</code></strong> package</a> has similar functionality to <strong><code class="language-plaintext highlighter-rouge">limma</code></strong> but allows the inclusion of random effects.</li>
</ul>

<h2 id="footnotes">Footnotes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>“True difference” is a hard category to rigidly define. As we’ve
seen, with a lot of data, we can detect tiny differences, and with
little data, we can’t detect large differences. However, both can be
argued to be “true”. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Bonferroni correction is also termed “family-wise” error rate
control. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>This is often called “Benjamini-Hochberg” adjustment. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>People often perform extra controls on FDR-adjusted p-values,
ensuring that ranks don’t change and the critical value is never
smaller than the original p-value. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>





<blockquote class="keypoints">
  <h2>Key Points</h2>
  <ul>
    
    <li><p>Performing linear regression in a high-dimensional setting requires us to perform hypothesis testing in a way that low-dimensional regression may not.</p>
</li>
    
    <li><p>Sharing information between features can increase power and reduce false positives.</p>
</li>
    
    <li><p>When running a lot of null hypothesis tests for high-dimensional data, multiple testing correction allows retain power and avoid making costly false discoveries.</p>
</li>
    
    <li><p>Multiple testing methods can be more conservative or more liberal, depending on our goals.</p>
</li>
    
  </ul>
</blockquote>

</article>


















  
  











<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="../01-introduction-to-high-dimensional-data/index.html"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="../03-regression-regularisation/index.html"><span class="glyphicon glyphicon-menu-right" aria-hidden="true"></span><span class="sr-only">next episode</span></a>
      
    </h3>
  </div>
</div>



      
      






<footer>
  <hr/>
  <div class="row">
    <div class="col-md-6 license" id="license-info" align="left">
	
        Licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a> 2024 by <a href="../CITATION">the authors</a>.
	
    </div>
    <div class="col-md-6 help-links" align="right">
	
	
	<a href="/edit//_episodes_rmd/02-high-dimensional-regression.Rmd" data-checker-ignore>Edit on GitHub</a>
	
	
	/
	<a href="/blob//CONTRIBUTING.md" data-checker-ignore>Contributing</a>
	/
	<a href="/">Source</a>
	/
	<a href="/blob//CITATION" data-checker-ignore>Cite</a>
	/
	<a href="mailto:alan.ocallaghan@outlook.com">Contact</a>
    </div>
  </div>
  <p class="text-muted text-right">
    <small><i>Using <a href="https://github.com/carpentries/carpentries-theme/">The Carpentries theme</a> &mdash; Site last built on: 2024-02-26 23:12:36 +0000.</i></small>
  </p>
</footer>

      
    </div>
    
<script src="../assets/js/jquery.min.js"></script>
<script src="../assets/js/bootstrap.min.js"></script>
<script src="../assets/js/lesson.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-37305346-2', 'auto');
  ga('send', 'pageview');
</script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
        },
        "HTML-CSS": { fonts: ["TeX"] }
      });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  </body>
</html>
